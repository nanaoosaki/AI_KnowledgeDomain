---
layout: default
title: ğŸŒ± 1. At the programming-language level
parent: Systems & Infrastructure
---

*[â† Back to Systems & Infrastructure](README.md)*

---

# ğŸŒ± **1. At the programming-language level**

### **Imperative**

You tell the computer **how** to do something, step by step.

Think of it as giving instructions like a recipe:

* do this
* then do that
* then loop here
* store this result

Examples:

* Python
* Java
* C/C++
* Rust
* JavaScript (in general usage)

Characteristics:

* Explicit control flow
* Mutating state
* Focus on *operations*
* Debugging feels concrete (you can trace execution)

---

### **Declarative**

You tell the computer **what** you want, not how to do it.

More like describing the final state or the rule:

* this is the transformation
* these are the constraints
* this is the relationship

Examples:

* SQL (you tell *what* you want, not how to scan tables)
* HTML (what structure should look like)
* CSS (desired visual layout)
* Regex (patterns)
* Functional programming languages (Haskell, some Scala)
* Neural network layer declarations (Keras)

Characteristics:

* You do NOT specify loops, iterative steps, or state changes
* You express intent
* The engine decides how to execute efficiently

---

# ğŸŒ² **2. At the framework level**

This is where PyTorch vs TensorFlow fits perfectly.

### **Imperative frameworks (PyTorch)**

You write the forward pass like Python code:

```python
output = model(x)
loss = criterion(output, y)
loss.backward()
optimizer.step()
```

Control is explicit.
Debugging is easy.
Feels like imperative Python.

---

### **Declarative frameworks (Keras / TensorFlow)**

You define the *shape* of the model and let the framework handle training:

```python
model = keras.Sequential([...])
model.compile(...)
model.fit(...)
```

You describe:

* the structure
* the metrics
* the optimizer
  â€¦and TF orchestrates the rest.

When you add `@tf.function`, you move even more into graph executionâ€”TensorFlow turns your code into a **computational graph**, a declarative representation.

---

# ğŸŒ³ **3. At the software-engineering patterns / mindset level**

This split shows up in *how humans think about systems*.

### **Imperative thinking**

* Focus on *steps & flows*
* Detailed control
* More moving parts to manage
* Great for fine-grained logic

Typical in:

* game engines
* simulations
* low-level systems
* device drivers
* custom ML training loops

---

### **Declarative thinking**

* Focus on *rules & desired outcomes*
* System handles execution strategy
* More composable, scalable
* Often easier to reason about large systems

Typical in:

* UI frameworks declarative rendering (React, SwiftUI)
* Infrastructure as code (Terraform)
* Database queries (SQL)
* Build systems (Bazel)
* ML pipeline orchestration (Airflow DAGs, TFX)

React is a perfect example:

* You **declare** what UI should look like given state.
* The framework figures out how to update DOM.

---

# ğŸŒ² **4. Typical trade-offs**

### **Imperative â†’ pros**

* Very flexible
* Easy to debug
* Great when control matters
* Transparent behavior

### **Imperative â†’ cons**

* More boilerplate
* Harder to maintain at scale
* More error-prone

---

### **Declarative â†’ pros**

* Cleaner, higher-level
* Less code to maintain
* More optimization opportunities
* Parallelization or optimization becomes the systemâ€™s job

### **Declarative â†’ cons**

* Can feel â€œmagicalâ€ and harder to debug
* Less fine-grained control
* Performance quirks can be opaque

---

# ğŸŒ‰ **5. Connecting everything**

Think of them as two styles of telling a system what to do.

### **Imperative is:**

â€œFirst fold the dough, preheat the oven, then mixâ€¦ then bake.â€

### **Declarative is:**

â€œI want a sourdough loaf.â€
(The baker chooses the steps.)

---

# ğŸ§  **How this helps**

Understanding this helps you:

* pick tools
* debug behavior
* design cleaner architecture
* communicate technical tradeoffs to others

Examples:

* Writing a PyTorch training loop â†’ imperative
* Defining a HF `Trainer` config â†’ declarative
* Writing SQL for feature extraction â†’ declarative
* Writing RAG pipelines where you orchestrate steps manually â†’ imperative
* Terraforming cloud infra â†’ declarative
* Writing Next.js JSX â†’ declarative
* Custom evaluation / prompt engineering loops â†’ imperative

---

# ğŸŒŸ **Scikit-learn (Python)** â†’ *Mostly declarative on top, imperative underneath*

Even though scikit-learn is written in Python (an imperative language), the **API style** is **declarative**.

You donâ€™t tell it *how* to train a model step-by-step.

You tell it things like:

```python
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)
pred = model.predict(X_test)
```

Youâ€™re not writing the loops, gradients, splits, impurity calculations, or predictions.
Youâ€™re describing:

* the model type
* the parameters
* the data

â€¦and scikit-learn handles the execution.

**Declarative traits of scikit-learn:**

* You *declare* the model structure (`RandomForestClassifier(...)`)
* You *declare* hyperparameters
* You *declare* transformations in Pipelines
* The library handles optimization, algorithms, flow
* You do not specify how to update weights or compute impurity

Under the hood, scikit-learn *is imperative*, but the user experience is **strongly declarative**.

---

# ğŸŒŸ **SAS** â†’ *Very declarative*

SAS is actually one of the clearest examples of declarative analytics.

In SAS PROC syntax, you tell SAS:

* what dataset to read
* what statistical method to use
* what output you want

Example:

```sas
PROC REG DATA=mydata;
    MODEL y = x1 x2 x3;
RUN;
```

Youâ€™re not writing loops, derivatives, optimizers.
Youâ€™re declaring:

* the regression
* the variables
* the data source

and SAS executes.

**SAS is way more declarative than Python/scikit-learn.**

Itâ€™s closer to SQL in philosophy.

---

# ğŸŒŸ **R** â†’ *mostly declarative, semi-functional*

R is an interesting hybrid:

### **Base R modeling (like `lm`, `glm`) is declarative:**

```r
fit <- lm(y ~ x1 + x2 + x3, data=df)
```

* You declare the formula
* You declare the model family
* R figures out the math

The formula interface (`y ~ x1 + x2 + x3`) is one of the most declarative modeling interfaces ever designed.

### **dplyr / tidyverse** is also declarative:

```r
df %>%
  filter(x > 0) %>%
  group_by(category) %>%
  summarize(mean_y = mean(y))
```

You describe *what* you want, not the loops.

### **R for-loop code is imperative**, but used far less frequently.

Overall, **R is closer to declarative functional style than Python**.

---

# ğŸŒŸ **Comparative summary**

| Tool             | Language            | User-Level Style                         | Why                                          |
| ---------------- | ------------------- | ---------------------------------------- | -------------------------------------------- |
| **Scikit-learn** | Python (imperative) | **Declarative high-level API**           | You declare models; library handles training |
| **SAS**          | SAS language        | **Strongly declarative**                 | PROC steps describe â€œwhat,â€ not â€œhowâ€        |
| **R**            | Functional-ish      | **Mostly declarative** (formulas, dplyr) | You describe transformations; engine runs it |

---

# ğŸŒŸ **If we rank them from most declarative â†’ most imperative**

**Most declarative**

1. **SAS**
2. **R (tidyverse & formula modeling)**
3. **Scikit-learn**
4. **PyTorch (imperative)**
5. **Raw Python loops (very imperative)**
   **Most imperative**

TensorFlow/Keras (in `model.fit()` mode) would sit between scikit-learn and R.

---

# ğŸŒŸ How this helps

Knowing the stance of each tool helps you pick what's appropriate for:

* **rapid experimentation** â†’ declarative (R, sklearn, Keras)
* **deep customization** â†’ imperative (PyTorch)
* **production pipelines** â†’ declarative (SAS, sklearn pipelines, TFX)
* **research** â†’ imperative (PyTorch)
* **teaching / clarity** â†’ declarative (R formulas)
